{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b224146",
   "metadata": {},
   "source": [
    "# Projet de Data Mining (EPSI Rennes) - Application de la Méthodologie CRISP-DM\n",
    "## (Version Finale Corrigée et Structurée)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeda0ec",
   "metadata": {},
   "source": [
    "### Phase 1-3 : Business & Data Understanding, Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. IMPORT DES LIBRAIRIES\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afb2db",
   "metadata": {},
   "source": [
    "### Étape 1 : Préparation Complète des Données (Nettoyage + Feature Engineering)\n",
    "Ce bloc exécute toutes les étapes de préparation en une seule fois pour garantir la présence de toutes les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3860d47",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- 1.1 Chargement et Nettoyage ---\n",
    "df = pd.read_csv('fr-esr-insertion_professionnelle-master.csv', sep=';')\n",
    "\n",
    "columns_mapping = {\n",
    "    'annee': 'annee_diplome', 'discipline': 'discipline',\n",
    "    'academie': 'academie', 'taux_dinsertion': 'taux_insertion',\n",
    "    'emplois_stables': 'taux_emploi_stable',\n",
    "    'salaire_net_median_des_emplois_a_temps_plein': 'salaire_median',\n",
    "    'emplois_cadre': 'taux_emploi_cadre', 'femmes': 'part_femmes'\n",
    "}\n",
    "df_cleaned = df[columns_mapping.keys()].copy()\n",
    "df_cleaned.rename(columns=columns_mapping, inplace=True)\n",
    "\n",
    "cols_to_numeric = df_cleaned.columns.drop(['discipline', 'academie'])\n",
    "for col in cols_to_numeric:\n",
    "    df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
    "\n",
    "df_cleaned.dropna(subset=['taux_insertion', 'salaire_median', 'academie'], inplace=True)\n",
    "\n",
    "for col in ['taux_emploi_stable', 'taux_emploi_cadre', 'part_femmes']:\n",
    "    group_median = df_cleaned.groupby('discipline')[col].transform('median')\n",
    "    df_cleaned[col].fillna(group_median, inplace=True)\n",
    "    df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "\n",
    "df_cleaned.drop_duplicates(inplace=True)\n",
    "\n",
    "# --- 1.2 Feature Engineering (Création des nouvelles colonnes) ---\n",
    "\n",
    "# Feature 1 : Région administrative\n",
    "region_mapping = {\n",
    "    'Aix-Marseille': \"Provence-Alpes-Côte d'Azur\", 'Amiens': 'Hauts-de-France', 'Besançon': 'Bourgogne-Franche-Comté',\n",
    "    'Bordeaux': 'Nouvelle-Aquitaine', 'Clermont-Ferrand': 'Auvergne-Rhône-Alpes', 'Corse': 'Corse',\n",
    "    'Créteil': 'Île-de-France', 'Dijon': 'Bourgogne-Franche-Comté', 'Grenoble': 'Auvergne-Rhône-Alpes',\n",
    "    'Guadeloupe': 'Guadeloupe', 'Guyane': 'Guyane', 'Lille': 'Hauts-de-France', 'Limoges': 'Nouvelle-Aquitaine',\n",
    "    'Lyon': 'Auvergne-Rhône-Alpes', 'Martinique': 'Martinique', 'Mayotte': 'Mayotte', 'Montpellier': 'Occitanie',\n",
    "    'Nancy-Metz': 'Grand Est', 'Nantes': 'Pays de la Loire', 'Nice': \"Provence-Alpes-Côte d'Azur\",\n",
    "    'Normandie': 'Normandie', 'Orléans-Tours': 'Centre-Val de Loire', 'Paris': 'Île-de-France',\n",
    "    'Poitiers': 'Nouvelle-Aquitaine', 'Reims': 'Grand Est', 'Rennes': 'Bretagne', 'La Réunion': 'La Réunion',\n",
    "    'Strasbourg': 'Grand Est', 'Toulouse': 'Occitanie', 'Versailles': 'Île-de-France'\n",
    "}\n",
    "df_cleaned['region'] = df_cleaned['academie'].map(region_mapping)\n",
    "df_cleaned.dropna(subset=['region'], inplace=True)\n",
    "\n",
    "# Feature 2 : Grand Domaine\n",
    "conditions = [\n",
    "    df_cleaned['discipline'].str.contains('Droit|Gestion|Economie|AES|Commerce', case=False, na=False),\n",
    "    df_cleaned['discipline'].str.contains('Lettre|Langue|Art|Communication|Traduction|Journalisme', case=False, na=False),\n",
    "    df_cleaned['discipline'].str.contains('Humaine|Sociale|Histoire|Géographie|Socio|Psycho|Philo', case=False, na=False),\n",
    "    df_cleaned['discipline'].str.contains('Enseignement|MEEF', case=False, na=False),\n",
    "    df_cleaned['discipline'].str.contains('Science|Technologie|Santé|Ingénierie|Informatique|Math|Biologie|Physique|Chimie|STAPS', case=False, na=False)\n",
    "]\n",
    "choices = ['Droit, Éco & Gestion', 'Arts, Lettres & Langues', 'Sciences Humaines & Sociales', 'Enseignement', 'Sciences & Tech']\n",
    "df_cleaned['grand_domaine'] = np.select(conditions, choices, default='Autres disciplines')\n",
    "\n",
    "# Feature 3 : Indice d'Attractivité\n",
    "salaire_norm = (df_cleaned['salaire_median'] - df_cleaned['salaire_median'].min()) / (df_cleaned['salaire_median'].max() - df_cleaned['salaire_median'].min())\n",
    "insertion_norm = (df_cleaned['taux_insertion'] - df_cleaned['taux_insertion'].min()) / (df_cleaned['taux_insertion'].max() - df_cleaned['taux_insertion'].min())\n",
    "df_cleaned['indice_attractivite'] = (0.6 * salaire_norm + 0.4 * insertion_norm) * 100\n",
    "\n",
    "# Feature 4 : Qualité de l'Emploi\n",
    "conditions_qualite = [\n",
    "    (df_cleaned['taux_emploi_stable'] >= 80) & (df_cleaned['taux_emploi_cadre'] >= 80),\n",
    "    (df_cleaned['taux_emploi_stable'] >= 65) & (df_cleaned['taux_emploi_cadre'] >= 65),\n",
    "]\n",
    "choices_qualite = ['Excellente', 'Élevée']\n",
    "df_cleaned['qualite_emploi'] = np.select(conditions_qualite, choices_qualite, default='Standard')\n",
    "\n",
    "# Feature 5 : Parité\n",
    "df_cleaned['parite'] = pd.cut(df_cleaned['part_femmes'], bins=[0, 40, 60, 101], labels=['Majorité Masculine', 'Mixte', 'Majorité Féminine'], right=False)\n",
    "\n",
    "print(\"Préparation et Feature Engineering terminés. Dimensions finales :\", df_cleaned.shape)\n",
    "print(\"\\nColonnes présentes dans le DataFrame :\", df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c43905",
   "metadata": {},
   "source": [
    "### Étape 2 : Modélisation (Clustering et Régression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clustering K-Means ---\n",
    "cluster_data = df_cleaned.groupby('academie').agg(\n",
    "    salaire_median=('salaire_median', 'mean'),\n",
    "    taux_insertion=('taux_insertion', 'mean'),\n",
    "    taux_emploi_stable=('taux_emploi_stable', 'mean'),\n",
    "    taux_emploi_cadre=('taux_emploi_cadre', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cluster_features = ['salaire_median', 'taux_insertion', 'taux_emploi_stable', 'taux_emploi_cadre']\n",
    "cluster_data_scaled = scaler.fit_transform(cluster_data[cluster_features])\n",
    "\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_data['cluster'] = kmeans.fit_predict(cluster_data_scaled)\n",
    "\n",
    "# On fusionne les résultats du clustering dans notre dataframe principal\n",
    "df_final = df_cleaned.merge(cluster_data[['academie', 'cluster']], on='academie', how='left')\n",
    "df_final['cluster'] = df_final['cluster'].astype('category')\n",
    "\n",
    "# --- Régression RandomForest ---\n",
    "features = ['grand_domaine', 'region']\n",
    "target = 'salaire_median'\n",
    "X = df_final[features]\n",
    "y = df_final[target]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), features)])\n",
    "model_regression = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "model_regression.fit(X, y)\n",
    "\n",
    "print(\"\\nModèles de Clustering et Régression entraînés.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ac2f9c",
   "metadata": {},
   "source": [
    "### Étape 3 : Export des Artefacts (Données, Modèles, WordClouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d03c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text Mining ---\n",
    "article_1_text = \"L’insertion professionnelle des jeunes diplômés à un niveau record. La conjoncture a été particulièrement favorable aux sortants de l’enseignement supérieur en 2022. Le taux d’emploi des diplômés de master atteint 93 %, un an après la fin de leurs études, et ce, malgré l’inflation. Les salaires aussi sont en hausse. Le secteur des services et de l'industrie tirent la croissance.\"\n",
    "article_2_text = \"Insertion des jeunes diplômés 2024 : la confirmation des difficultés des jeunes femmes. Malgré un marché de l’emploi cadre dynamique, les jeunes femmes connaissent toujours des conditions d’insertion moins favorables que les hommes. Elles accèdent moins souvent au statut cadre et au CDI. L'écart de salaire persiste, notamment dans les fonctions informatiques et de la R&D. Les compétences techniques sont valorisées.\"\n",
    "\n",
    "def process_text_for_wordcloud(text, custom_stopwords=[]):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    try: stop_words = set(stopwords.words('french'))\n",
    "    except LookupError: nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    stop_words.update(custom_stopwords)\n",
    "    cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return \" \".join(cleaned_tokens)\n",
    "\n",
    "custom_stopwords = ['cest', 'dun', 'dune', 'plus', 'apec', 'cette']\n",
    "cleaned_text_1 = process_text_for_wordcloud(article_1_text, custom_stopwords)\n",
    "cleaned_text_2 = process_text_for_wordcloud(article_2_text, custom_stopwords)\n",
    "wordcloud_1 = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(cleaned_text_1)\n",
    "wordcloud_2 = WordCloud(width=800, height=400, background_color='white', colormap='plasma').generate(cleaned_text_2)\n",
    "wordcloud_1.to_file(\"wordcloud_article1.png\")\n",
    "wordcloud_2.to_file(\"wordcloud_article2.png\")\n",
    "\n",
    "# --- Sauvegarde des livrables ---\n",
    "df_final.to_csv('insertion_pro_master_final_v2.csv', index=False)\n",
    "joblib.dump(model_regression, 'salary_predictor_model.joblib')\n",
    "\n",
    "print(\"\\nExport terminé : 'insertion_pro_master_final_v2.csv', 'salary_predictor_model.joblib', et les WordClouds sont prêts.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
