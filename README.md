# üöÄ Projet de Data Mining : Analyse de l'Insertion des Dipl√¥m√©s de Master

**Projet r√©alis√© dans le cadre du module "Data Management, Data Visualisation & Text Mining" Sorbonne.**

Ce projet vise √† analyser en profondeur les dynamiques d'insertion professionnelle des titulaires de Master en France, en transformant des donn√©es brutes en un outil d'aide √† la d√©cision interactif.

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](LIEN_VERS_VOTRE_APP_STREAMLIT)  <!-- Mettez ici le lien si vous d√©ployez l'app -->

## üéØ Objectifs du Projet

L'objectif principal √©tait de d√©velopper une application web interactive avec Streamlit pour :
- **Explorer** les donn√©es sur les taux d'emploi et les salaires.
- **Visualiser** les disparit√©s g√©ographiques et sectorielles.
- **Mod√©liser** les donn√©es pour d√©couvrir des profils cach√©s (clustering) et pr√©dire des tendances (r√©gression).
- **Communiquer** les r√©sultats de mani√®re claire et actionnable.

## ‚öôÔ∏è M√©thodologie : CRISP-DM

Notre travail a rigoureusement suivi la m√©thodologie **CRISP-DM (Cross-Industry Standard Process for Data Mining)**, la norme industrielle pour les projets de science des donn√©es.

1.  **Business Understanding :** Comprendre le besoin : aider les √©tudiants √† s'orienter et les universit√©s √† se positionner.
2.  **Data Understanding :** Explorer le jeu de donn√©es de data.gouv.fr pour en comprendre la structure, les forces et les faiblesses.
3.  **Data Preparation :** Phase la plus critique.
    - **Nettoyage :** Traitement des valeurs manquantes (`'ns'`) et imputation intelligente par la m√©diane de groupe pour pr√©server la coh√©rence des donn√©es.
    - **Feature Engineering :** Cr√©ation de 5 variables √† forte valeur ajout√©e (`Grand Domaine`, `Indice d'Attractivit√©`, `Qualit√© de l'Emploi`, `Parit√©`, `R√©gion`) pour enrichir l'analyse.
4.  **Modeling :** Application de deux techniques de Data Mining.
    - **Clustering (K-Means) :** Pour segmenter les acad√©mies en 4 profils de performance distincts et d√©couvrir des structures g√©ographiques et √©conomiques sous-jacentes.
    - **R√©gression (Random Forest) :** Pour cr√©er un mod√®le pr√©dictif capable d'estimer un salaire m√©dian en fonction de la fili√®re et de la r√©gion.
5.  **Evaluation :**
    - Analyse de la m√©thode du coude pour choisir le nombre optimal de clusters.
    - Analyse qualitative des r√©sultats des mod√®les pour s'assurer qu'ils ont un "sens m√©tier".
6.  **Deployment :**
    - D√©veloppement d'un dashboard interactif avec **Streamlit**.
    - Cr√©ation de visualisations claires et comment√©es (cartes, boxplots, bubble charts, etc.) pour communiquer les r√©sultats.
    - Int√©gration d'une analyse **Text Mining** comparative de la presse pour contextualiser les donn√©es chiffr√©es.

## üîß Environnement Technique

- **Langage :** Python 3
- **Librairies principales :**
  - **Analyse de donn√©es :** Pandas, NumPy
  - **Mod√©lisation :** Scikit-learn
  - **Dataviz :** Plotly Express, Matplotlib
  - **Application Web :** Streamlit
  - **Text Mining :** WordCloud, NLTK

## üöÄ Comment Lancer le Projet

1.  **Cloner le d√©p√¥t :**
    ```bash
    git clone [https://github.com/UtmostMaker/projet-datamining_insertion_master]
    cd projet-datamining_insertion_master
    ```
2.  **Cr√©er un environnement virtuel :**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```
3.  **Installer les d√©pendances :**
    ```bash
    pip install -r requirements.txt
    ```
4.  **T√©l√©charger les donn√©es NLTK :**
    ```python
    # Lancer python3 et ex√©cuter :
    import nltk
    nltk.download('stopwords')
    ```
5.  **Ex√©cuter l'application Streamlit :**
    ```bash
    streamlit run app.py
    ```

## üë• Auteurs

- Pr√©nom NOM 1
- Pr√©nom NOM 2
- Pr√©nom NOM 3
